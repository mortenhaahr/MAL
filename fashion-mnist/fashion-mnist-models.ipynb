{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bita0a693ad8d68456caa33da3049e16cf6",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.4.3\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class ImageFloatConverter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        from skimage import img_as_float \n",
    "        import numpy as np\n",
    "    \n",
    "        X_ = np.zeros(X.shape, dtype=np.float)\n",
    "        for i in range(X.shape[0]):\n",
    "            X_[i] = img_as_float(X[i])\n",
    "        return X_\n",
    "    \n",
    "scaler = ImageFloatConverter()\n",
    "x = scaler.transform(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.842170943040401e-14"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Test scaler max deviation\n",
    "np.max(np.abs(x[42] * 255 - X_train[42]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAsSerial(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        import numpy as np\n",
    "        X_ = np.zeros((X.shape[0], X.shape[1] * X.shape[2]), dtype=np.float)\n",
    "        for i in range(X.shape[0]):\n",
    "            X_[i] = X[i].ravel()\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ImageFloatConverter', ImageFloatConverter()),\n",
       "                ('Serialize', ImageAsSerial()),\n",
       "                ('SGDClassifier', SGDClassifier(max_iter=100))])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Test that the Pipeline is working - not necessary to run.\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('ImageFloatConverter', ImageFloatConverter()),\n",
    "    ('Serialize', ImageAsSerial()),\n",
    "    ('SGDClassifier', SGDClassifier(max_iter=100, tol=1e-3))])\n",
    "\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8327"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "source": [
    "# Test af modeller"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "model = Pipeline([\n",
    "                ('ImageFloatConverter', ImageFloatConverter()),\n",
    "                ('Serialize', ImageAsSerial()),\n",
    "                ('SGDClassifier', SGDClassifier(max_iter=100, tol=1e-3))]\n",
    "            )\n",
    "            \n",
    "model.fit(X_train, y_train)\n",
    "sgd_score = model.score(X_test, y_test)\n",
    "print(sgd_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/morten/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "0.8396\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = Pipeline([\n",
    "                ('ImageFloatConverter', ImageFloatConverter()),\n",
    "                ('Serialize', ImageAsSerial()),\n",
    "                ('LinearSVC', LinearSVC())]\n",
    "            )\n",
    "            \n",
    "model.fit(X_train, y_train)\n",
    "lsvc_score = model.score(X_test, y_test)\n",
    "print(lsvc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8554\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = Pipeline([\n",
    "                ('ImageFloatConverter', ImageFloatConverter()),\n",
    "                ('Serialize', ImageAsSerial()),\n",
    "                ('KNeighborsClassifier', KNeighborsClassifier())]\n",
    "            )\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "knn_score = model.score(X_test, y_test)\n",
    "print(knn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/morten/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "0.8783\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = Pipeline([\n",
    "                ('ImageFloatConverter', ImageFloatConverter()),\n",
    "                ('Serialize', ImageAsSerial()),\n",
    "                ('MLPClassifier', MLPClassifier())]\n",
    "            )\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "mlp_score = model.score(X_test, y_test)\n",
    "print(mlp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.5377 - accuracy: 0.8087\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3250 - accuracy: 0.8837\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# SOURCE: https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-fashion-mnist-clothing-classification/\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
    "\t# reshape dataset to have a single channel\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.01, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "trainX, trainY, testX, testY = load_dataset()\n",
    "trainX, testX = prep_pixels(trainX, testX)\n",
    "model = define_model()\n",
    "model.fit(trainX, trainY)\n",
    "eval = model.evaluate(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 26, 26, 32)        320       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 5408)              0         \n_________________________________________________________________\ndense (Dense)                (None, 100)               540900    \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                1010      \n=================================================================\nTotal params: 542,230\nTrainable params: 542,230\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {} # Reset\n",
    "attempt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 42s 22ms/step - loss: 0.7512 - accuracy: 0.7652\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.3603 - accuracy: 0.8637\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 0.3078 - accuracy: 0.8871\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.2754 - accuracy: 0.8957\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.2472 - accuracy: 0.9066\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.3130 - accuracy: 0.8869\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=(3,3),\n",
    "                        activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.AveragePooling2D()) # 14x14 img\n",
    "\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D()) # 7x7 img\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(units=120, activation='relu'))\n",
    "model.add(layers.Dense(units=84, activation='relu'))\n",
    "model.add(layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "X_tmp = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "y_tmp = to_categorical(y_train)\n",
    "X_tmp_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
    "y_tmp_test = to_categorical(y_test)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='accuracy')\n",
    "model.fit(X_tmp, y_tmp, epochs=5)\n",
    "eval = model.evaluate(X_tmp_test, y_tmp_test)\n",
    "scores[f'attempt{attempt}'] = eval\n",
    "attempt = attempt + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'attempt0': [0.382768839597702, 0.864799976348877], 'attempt1': [0.40746375918388367, 0.8481000065803528], 'attempt2': [0.3130331039428711, 0.886900007724762]}\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.6449 - accuracy: 0.7704\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3699 - accuracy: 0.8648\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3295 - accuracy: 0.8778\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2981 - accuracy: 0.8893\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2781 - accuracy: 0.8944\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2613 - accuracy: 0.9012\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2502 - accuracy: 0.9075\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2325 - accuracy: 0.9120\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2293 - accuracy: 0.9137\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2097 - accuracy: 0.9202\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2010 - accuracy: 0.9244\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1940 - accuracy: 0.9281\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1870 - accuracy: 0.9298\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1803 - accuracy: 0.9299\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1718 - accuracy: 0.9356\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1662 - accuracy: 0.9378\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1578 - accuracy: 0.9409\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1525 - accuracy: 0.9445\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1443 - accuracy: 0.9450\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1444 - accuracy: 0.9457\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3716 - accuracy: 0.8880\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_11 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 159,010\n",
      "Trainable params: 159,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Example based on YouTube video: https://www.youtube.com/watch?v=oHAkK_9UCQ8\n",
    "\n",
    "X_train_norm = keras.utils.normalize(X_train, axis = 1)\n",
    "X_test_norm = keras.utils.normalize(X_test, axis = 1)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Flatten(input_shape=(28,28,1)))\n",
    "model.add(layers.Dense(200, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(X_train_norm, y_train, epochs=20)\n",
    "eval = model.evaluate(X_test_norm, y_test)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.37163376808166504, 0.8880000114440918]\n"
     ]
    }
   ],
   "source": [
    "print(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1875/1875 [==============================] - 37s 19ms/step - loss: 1.1731 - accuracy: 0.6533\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.5086 - accuracy: 0.8117\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 26, 26, 5)         50        \n",
      "_________________________________________________________________\n",
      "average_pooling2d_20 (Averag (None, 13, 13, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 11, 11, 5)         230       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_21 (Averag (None, 5, 5, 5)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 30)                3780      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 5,300\n",
      "Trainable params: 5,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 2.1907 - accuracy: 0.6528\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.5652 - accuracy: 0.7857\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 26, 26, 5)         50        \n",
      "_________________________________________________________________\n",
      "average_pooling2d_22 (Averag (None, 13, 13, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 11, 11, 5)         230       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_23 (Averag (None, 5, 5, 5)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 30)                3780      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 50)                1550      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 6,120\n",
      "Trainable params: 6,120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1875/1875 [==============================] - 46s 23ms/step - loss: 0.8714 - accuracy: 0.7013\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.4648 - accuracy: 0.8341\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 26, 26, 5)         50        \n",
      "_________________________________________________________________\n",
      "average_pooling2d_24 (Averag (None, 13, 13, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 11, 11, 5)         230       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_25 (Averag (None, 5, 5, 5)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 30)                3780      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 70)                2170      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 10)                710       \n",
      "=================================================================\n",
      "Total params: 6,940\n",
      "Trainable params: 6,940\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical\n",
    "import itertools\n",
    "\n",
    "def create_model(hyper_parameters, X_train, y_train, epochs):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(\n",
    "        layers.Conv2D(\n",
    "            filters=hyper_parameters['1_conv2d_filters'],\n",
    "            kernel_size=hyper_parameters['1_conv2d_kernel'],\n",
    "            activation=hyper_parameters['activation'],\n",
    "            input_shape=(28, 28, 1)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    model.add(layers.AveragePooling2D()) # 14x14 img\n",
    "\n",
    "    model.add(\n",
    "        layers.Conv2D(\n",
    "            filters=hyper_parameters['2_conv2d_filters'],\n",
    "            kernel_size=hyper_parameters['2_conv2d_kernel'],\n",
    "            activation=hyper_parameters['activation']\n",
    "        )\n",
    "    )\n",
    "        \n",
    "    model.add(layers.AveragePooling2D()) # 7x7 img\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(units=hyper_parameters['dense1_units'], activation=hyper_parameters['activation']))\n",
    "    model.add(layers.Dense(units=hyper_parameters['dense2_units'], activation=hyper_parameters['activation']))\n",
    "    model.add(layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "    model.fit(X_train, y_train, epochs=epochs)\n",
    "\n",
    "    return model\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_tuning, y_train_tuning), (X_test_tuning, y_test_tuning) = fashion_mnist.load_data()\n",
    "\n",
    "X_train_tuning = X_train_tuning.reshape((X_train_tuning.shape[0], 28, 28, 1))\n",
    "y_train_tuning = to_categorical(y_train_tuning)\n",
    "X_test_tuning = X_test_tuning.reshape((X_test_tuning.shape[0], 28, 28, 1))\n",
    "y_test_tuning = to_categorical(y_test_tuning)\n",
    "\n",
    "hyper_parameters_ranges = {\n",
    "            '1_conv2d_filters': list(range(5, 41, 10)),\n",
    "            '1_conv2d_kernel': [(3,3), (2, 2)],\n",
    "            'activation': ['relu'],\n",
    "            '2_conv2d_filters': list(range(5, 41, 10)),\n",
    "            '2_conv2d_kernel': [(3,3), (2, 2)],\n",
    "            'dense1_units':  list(range(30, 101, 20)),\n",
    "            'dense2_units': list(range(30, 101, 20))\n",
    "}\n",
    "\n",
    "# Convert from dict of ranges to list of dicts\n",
    "# https://stackoverflow.com/questions/38721847/how-to-generate-all-combination-from-values-in-dict-of-lists-in-python\n",
    "keys, values = zip(*hyper_parameters_ranges.items())\n",
    "hyper_parameters = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "for hyper_parameter in hyper_parameters[:3]:\n",
    "    model = create_model(hyper_parameter, X_train_tuning, y_train_tuning, 1)\n",
    "    eval = model.evaluate(X_test_tuning, y_test_tuning)\n",
    "    model.summary()\n",
    "\n",
    "    result = f\"\"\"\n",
    "    With hyper_parameters:\n",
    "    {hyper_parameter}.\n",
    "    Result: {eval}.\n",
    "\n",
    "    \"\"\"\n",
    "    with open('results.txt', 'a') as file:\n",
    "        file.write(result)"
   ]
  }
 ]
}