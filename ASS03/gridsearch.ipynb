{
 "cells": [
  {
   "source": [
    "### Qa) Forklaring til hvad GridSearch er\n",
    "Den første opgave bestod af at forklare, hvad GridSearch helt konkret er. Der blev givet to kodeceller, hvortil den første skulle beskrives overfladisk, og den anden skulle beskrives mere dybdegående, ved de steder, hvor GridSearch fremtræder."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "OK(function setup, hope MNIST loads works, seem best if you got Keras or Tensorflow installed!)\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn import datasets\n",
    "\n",
    "from libitmal import dataloaders as itmaldataloaders # Needed for load of iris, moon and mnist\n",
    "\n",
    "currmode=\"N/A\" # GLOBAL var!\n",
    "\n",
    "def SearchReport(model): \n",
    "    \n",
    "    def GetBestModelCTOR(model, best_params):\n",
    "        def GetParams(best_params):\n",
    "            ret_str=\"\"          \n",
    "            for key in sorted(best_params):\n",
    "                value = best_params[key]\n",
    "                temp_str = \"'\" if str(type(value))==\"<class 'str'>\" else \"\"\n",
    "                if len(ret_str)>0:\n",
    "                    ret_str += ','\n",
    "                ret_str += f'{key}={temp_str}{value}{temp_str}'  \n",
    "            return ret_str          \n",
    "        try:\n",
    "            param_str = GetParams(best_params)\n",
    "            return type(model).__name__ + '(' + param_str + ')' \n",
    "        except:\n",
    "            return \"N/A(1)\"\n",
    "        \n",
    "    print(\"\\nBest model set found on train set:\")\n",
    "    print()\n",
    "    print(f\"\\tbest parameters={model.best_params_}\")\n",
    "    print(f\"\\tbest '{model.scoring}' score={model.best_score_}\")\n",
    "    print(f\"\\tbest index={model.best_index_}\")\n",
    "    print()\n",
    "    print(f\"Best estimator CTOR:\")\n",
    "    print(f\"\\t{model.best_estimator_}\")\n",
    "    print()\n",
    "    try:\n",
    "        print(f\"Grid scores ('{model.scoring}') on development set:\")\n",
    "        means = model.cv_results_['mean_test_score']\n",
    "        stds  = model.cv_results_['std_test_score']\n",
    "        i=0\n",
    "        for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "            print(\"\\t[%2d]: %0.3f (+/-%0.03f) for %r\" % (i, mean, std * 2, params))\n",
    "            i += 1\n",
    "    except:\n",
    "        print(\"WARNING: the random search do not provide means/stds\")\n",
    "    \n",
    "    global currmode                \n",
    "    assert \"f1_micro\"==str(model.scoring), f\"come on, we need to fix the scoring to be able to compare model-fits! Your scoreing={str(model.scoring)}...remember to add scoring='f1_micro' to the search\"   \n",
    "    return f\"best: dat={currmode}, score={model.best_score_:0.5f}, model={GetBestModelCTOR(model.estimator,model.best_params_)}\", model.best_estimator_ \n",
    "\n",
    "def ClassificationReport(model, X_test, y_test, target_names=None):\n",
    "    assert X_test.shape[0]==y_test.shape[0]\n",
    "    print(\"\\nDetailed classification report:\")\n",
    "    print(\"\\tThe model is trained on the full development set.\")\n",
    "    print(\"\\tThe scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, model.predict(X_test)                 \n",
    "    print(classification_report(y_true, y_pred, target_names))\n",
    "    print()\n",
    "    \n",
    "def FullReport(model, X_test, y_test, t):\n",
    "    beststr, bestmodel = SearchReport(model)\n",
    "    ClassificationReport(model, X_test, y_test)    \n",
    "    print(f\"SEARCH TIME: {t:0.2f} sec\")\n",
    "    print(f\"CTOR for best model: {bestmodel}\\n\")\n",
    "    print(f\"{beststr}\\n\")\n",
    "    return beststr, bestmodel\n",
    "    \n",
    "def LoadAndSetupData(mode, test_size=0.3):\n",
    "    assert test_size>=0.0 and test_size<=1.0\n",
    "    \n",
    "    def ShapeToString(Z):\n",
    "        n = Z.ndim\n",
    "        s = \"(\"\n",
    "        for i in range(n):\n",
    "            s += f\"{Z.shape[i]:5d}\"\n",
    "            if i+1!=n:\n",
    "                s += \";\"\n",
    "        return s+\")\"\n",
    "\n",
    "    global currmode\n",
    "    currmode=mode\n",
    "    print(f\"DATA: {currmode}..\")\n",
    "    \n",
    "    if mode=='moon':\n",
    "        X, y = itmaldataloaders.MOON_GetDataSet(n_samples=5000, noise=0.2)\n",
    "        itmaldataloaders.MOON_Plot(X, y)\n",
    "    elif mode=='mnist':\n",
    "        X, y = itmaldataloaders.MNIST_GetDataSet(load_mode=0)\n",
    "        if X.ndim==3:\n",
    "            X=np.reshape(X, (X.shape[0], -1))\n",
    "    elif mode=='iris':\n",
    "        X, y = itmaldataloaders.IRIS_GetDataSet()\n",
    "    else:\n",
    "        raise ValueError(f\"could not load data for that particular mode='{mode}', only 'moon'/'mnist'/'iris' supported\")\n",
    "        \n",
    "    print(f'  org. data:  X.shape      ={ShapeToString(X)}, y.shape      ={ShapeToString(y)}')\n",
    "\n",
    "    assert X.ndim==2\n",
    "    assert X.shape[0]==y.shape[0]\n",
    "    assert y.ndim==1 or (y.ndim==2 and y.shape[1]==0)    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=0, shuffle=True\n",
    "    )\n",
    "    \n",
    "    print(f'  train data: X_train.shape={ShapeToString(X_train)}, y_train.shape={ShapeToString(y_train)}')\n",
    "    print(f'  test data:  X_test.shape ={ShapeToString(X_test)}, y_test.shape ={ShapeToString(y_test)}')\n",
    "    print()\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "print('OK(function setup, hope MNIST loads works, seem best if you got Keras or Tensorflow installed!)')"
   ]
  },
  {
   "source": [
    "### Qa) Fortsat:\n",
    "`SearchReport` - tager en trænet model og printer parametrene fra den bedste model.<br>\n",
    "`ClassificationReport` - Udskriver information fra Scikit-learns `classification_report` funktion, og gør det ud fra testdataen. <br>\n",
    "`LoadAndSetupData` - indlæser dataen og og opdeler i train/test-splits. <br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DATA: iris..\n",
      "  org. data:  X.shape      =(  150;    4), y.shape      =(  150)\n",
      "  train data: X_train.shape=(  105;    4), y_train.shape=(  105)\n",
      "  test data:  X_test.shape =(   45;    4), y_test.shape =(   45)\n",
      "\n",
      "SEARCH TIME: 0.13 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'C': 1, 'kernel': 'linear'}\n",
      "\tbest 'f1_micro' score=0.9714285714285715\n",
      "\tbest index=2\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSVC(C=1, gamma=0.001, kernel='linear')\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.962 (+/-0.093) for {'C': 0.1, 'kernel': 'linear'}\n",
      "\t[ 1]: 0.371 (+/-0.038) for {'C': 0.1, 'kernel': 'rbf'}\n",
      "\t[ 2]: 0.971 (+/-0.047) for {'C': 1, 'kernel': 'linear'}\n",
      "\t[ 3]: 0.695 (+/-0.047) for {'C': 1, 'kernel': 'rbf'}\n",
      "\t[ 4]: 0.952 (+/-0.085) for {'C': 10, 'kernel': 'linear'}\n",
      "\t[ 5]: 0.924 (+/-0.097) for {'C': 10, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "\n",
      "CTOR for best model: SVC(C=1, gamma=0.001, kernel='linear')\n",
      "\n",
      "best: dat=iris, score=0.97143, model=SVC(C=1,kernel='linear')\n",
      "\n",
      "OK(grid-search)\n",
      "/home/morten/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=None as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "# TODO: Qa, code review..cell 2) the actual grid-search\n",
    "\n",
    "# Setup data\n",
    "X_train, X_test, y_train, y_test = LoadAndSetupData(\n",
    "    'iris')  # 'iris', 'moon', or 'mnist'\n",
    "\n",
    "# Setup search parameters\n",
    "model = svm.SVC(\n",
    "    gamma=0.001\n",
    ")  # NOTE: gamma=\"scale\" does not work in older Scikit-learn frameworks,\n",
    "# FIX:  replace with model = svm.SVC(gamma=0.001)\n",
    "\n",
    "tuning_parameters = {\n",
    "    'kernel': ('linear', 'rbf'), \n",
    "    'C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "CV = 5\n",
    "VERBOSE = 0\n",
    "\n",
    "# Run GridSearchCV for the model\n",
    "start = time()\n",
    "grid_tuned = GridSearchCV(model,\n",
    "                          tuning_parameters,\n",
    "                          cv=CV,\n",
    "                          scoring='f1_micro',\n",
    "                          verbose=VERBOSE,\n",
    "                          n_jobs=-1)\n",
    "grid_tuned.fit(X_train, y_train)\n",
    "t = time() - start\n",
    "\n",
    "# Report result\n",
    "b0, m0 = FullReport(grid_tuned, X_test, y_test, t)\n",
    "print('OK(grid-search)')"
   ]
  },
  {
   "source": [
    "### Qa) Fortsat:\n",
    "Ud fra koden, kan det ses, at dataen først bliver loadet gennem funktionen `LoadAndSetupData`.<br>\n",
    "Derefter bliver algoritmen `SVC` (Support Vector Classification) valgt. I denne situation er der valgt ikke at prøve flere algoritmer, men det kunne gridsearch også have løst.<br>\n",
    "Efter dette bliver hyperparametrene bestemt, men modsat i de tidligere opgaver, bliver der nu oprettet en dictionary med lister/tuples af parametre. Dette indikerer hvilke hyperparametrer, som skal prøves i vores gridsearch. `GridSearchCV` modellen bliver derefter oprettet og fitted. Når en `GridSearchCV` model bliver fitted, er det lidt anderledes end det vi er vant til, for den forsøger at fitte med henblik på at finde de bedste hyperparametre. Den gør dette gennem en \"brute-force\" metode, hvor den prøver alle mulige kombinationer af de hyperparametre, som blev specificeret i vores dictionary.\n",
    "\n",
    "Hvad betyder det at der er blevet valgt scoringsmetoden `f1_micro`?<br>\n",
    "Det betyder at vi anvender en `f1_score` til at evaluere modellen men på \"micro\" niveau. Med dette menes at der kigges på alle klasser samlet i stedet for at score på de enkelte. Dette er fordelagtigt ved iris sættet, da vi har mange klasser, og ønsker at se den totale præstation (ikke med henblik på en enkelt label).\n",
    "\n",
    "\n",
    "Der blev valgt `n_jobs=-1` til algoritmen. Hvad betyder dette?<br>\n",
    "`n_jobs` angiver hvor mange tråde, der maksimalt skal dedikeres til at træne modellen. Når den sættes til -1, angiver det, at algoritmen skal bruge så mange tråde den kan. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Qb) Erstatning af SVC med SGD\n",
    "I denne opgave skal `SVC` algoritmen erstattes med en `SGD` algoritme. Der skal derefter foretages en gridsearch, som tager en ikke-ubetydelig mængde tid at eksekvere.\n",
    "\n",
    "Det ses af kodecellen nedenfor, at algoritmen er erstattet af en `SGDClassifier`. \n",
    "\n",
    "TODO: Skriv resultat."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ": 'constant', 'penalty': 'l2'}\n",
      "\t[79842]: 0.486 (+/-0.378) for {'alpha': 1.0, 'eta0': 0.8080808080808082, 'learning_rate': 'optimal', 'penalty': 'l1'}\n",
      "\t[79843]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.8080808080808082, 'learning_rate': 'optimal', 'penalty': 'l2'}\n",
      "\t[79844]: 0.562 (+/-0.279) for {'alpha': 1.0, 'eta0': 0.8080808080808082, 'learning_rate': 'invscaling', 'penalty': 'l1'}\n",
      "\t[79845]: 0.686 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.8080808080808082, 'learning_rate': 'invscaling', 'penalty': 'l2'}\n",
      "\t[79846]: 0.657 (+/-0.140) for {'alpha': 1.0, 'eta0': 0.8080808080808082, 'learning_rate': 'adaptive', 'penalty': 'l1'}\n",
      "\t[79847]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.8080808080808082, 'learning_rate': 'adaptive', 'penalty': 'l2'}\n",
      "\t[79848]: 0.371 (+/-0.251) for {'alpha': 1.0, 'eta0': 0.8181818181818182, 'learning_rate': 'constant', 'penalty': 'l1'}\n",
      "\t[79849]: 0.333 (+/-0.085) for {'alpha': 1.0, 'eta0': 0.8181818181818182, 'learning_rate': 'constant', 'penalty': 'l2'}\n",
      "\t[79850]: 0.390 (+/-0.140) for {'alpha': 1.0, 'eta0': 0.8181818181818182, 'learning_rate': 'optimal', 'penalty': 'l1'}\n",
      "\t[79851]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.8181818181818182, 'learning_rate': 'optimal', 'penalty': 'l2'}\n",
      "\t[79852]: 0.619 (+/-0.335) for {'alpha': 1.0, 'eta0': 0.8181818181818182, 'learning_rate': 'invscaling', 'penalty': 'l1'}\n",
      "\t[79853]: 0.648 (+/-0.214) for {'alpha': 1.0, 'eta0': 0.8181818181818182, 'learning_rate': 'invscaling', 'penalty': 'l2'}\n",
      "\t[79854]: 0.571 (+/-0.269) for {'alpha': 1.0, 'eta0': 0.8181818181818182, 'learning_rate': 'adaptive', 'penalty': 'l1'}\n",
      "\t[79855]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.8181818181818182, 'learning_rate': 'adaptive', 'penalty': 'l2'}\n",
      "\t[79856]: 0.400 (+/-0.222) for {'alpha': 1.0, 'eta0': 0.8282828282828284, 'learning_rate': 'constant', 'penalty': 'l1'}\n",
      "\t[79857]: 0.352 (+/-0.076) for {'alpha': 1.0, 'eta0': 0.8282828282828284, 'learning_rate': 'constant', 'penalty': 'l2'}\n",
      "\t[79858]: 0.400 (+/-0.230) for {'alpha': 1.0, 'eta0': 0.8282828282828284, 'learning_rate': 'optimal', 'penalty': 'l1'}\n",
      "\t[79859]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.8282828282828284, 'learning_rate': 'optimal', 'penalty': 'l2'}\n",
      "\t[79860]: 0.543 (+/-0.344) for {'alpha': 1.0, 'eta0': 0.8282828282828284, 'learning_rate': 'invscaling', 'penalty': 'l1'}\n",
      "\t[79861]: 0.676 (+/-0.338) for {'alpha': 1.0, 'eta0': 0.8282828282828284, 'learning_rate': 'invscaling', 'penalty': 'l2'}\n",
      "\t[79862]: 0.590 (+/-0.293) for {'alpha': 1.0, 'eta0': 0.8282828282828284, 'learning_rate': 'adaptive', 'penalty': 'l1'}\n",
      "\t[79863]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.8282828282828284, 'learning_rate': 'adaptive', 'penalty': 'l2'}\n",
      "\t[79864]: 0.314 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.8383838383838385, 'learning_rate': 'constant', 'penalty': 'l1'}\n",
      "\t[79865]: 0.352 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.8383838383838385, 'learning_rate': 'constant', 'penalty': 'l2'}\n",
      "\t[79866]: 0.400 (+/-0.316) for {'alpha': 1.0, 'eta0': 0.8383838383838385, 'learning_rate': 'optimal', 'penalty': 'l1'}\n",
      "\t[79867]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.8383838383838385, 'learning_rate': 'optimal', 'penalty': 'l2'}\n",
      "\t[79868]: 0.581 (+/-0.304) for {'alpha': 1.0, 'eta0': 0.8383838383838385, 'learning_rate': 'invscaling', 'penalty': 'l1'}\n",
      "\t[79869]: 0.695 (+/-0.214) for {'alpha': 1.0, 'eta0': 0.8383838383838385, 'learning_rate': 'invscaling', 'penalty': 'l2'}\n",
      "\t[79870]: 0.581 (+/-0.279) for {'alpha': 1.0, 'eta0': 0.8383838383838385, 'learning_rate': 'adaptive', 'penalty': 'l1'}\n",
      "\t[79871]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.8383838383838385, 'learning_rate': 'adaptive', 'penalty': 'l2'}\n",
      "\t[79872]: 0.324 (+/-0.071) for {'alpha': 1.0, 'eta0': 0.8484848484848485, 'learning_rate': 'constant', 'penalty': 'l1'}\n",
      "\t[79873]: 0.324 (+/-0.071) for {'alpha': 1.0, 'eta0': 0.8484848484848485, 'learning_rate': 'constant', 'penalty': 'l2'}\n",
      "\t[79874]: 0.571 (+/-0.289) for {'alpha': 1.0, 'eta0': 0.8484848484848485, 'learning_rate': 'optimal', 'penalty': 'l1'}\n",
      "\t[79875]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.8484848484848485, 'learning_rate': 'optimal', 'penalty': 'l2'}\n",
      "\t[79876]: 0.676 (+/-0.038) for {'alpha': 1.0, 'eta0': 0.8484848484848485, 'learning_rate': 'invscaling', 'penalty': 'l1'}\n",
      "\t[79877]: 0.752 (+/-0.203) for {'alpha': 1.0, 'eta0': 0.8484848484848485, 'learning_rate': 'invscaling', 'penalty': 'l2'}\n",
      "\t[79878]: 0.467 (+/-0.368) for {'alpha': 1.0, 'eta0': 0.8484848484848485, 'learning_rate': 'adaptive', 'penalty': 'l1'}\n",
      "\t[79879]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.8484848484848485, 'learning_rate': 'adaptive', 'penalty': 'l2'}\n",
      "\t[79880]: 0.362 (+/-0.177) for {'alpha': 1.0, 'eta0': 0.8585858585858587, 'learning_rate': 'constant', 'penalty': 'l1'}\n",
      "\t[79881]: 0.314 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.8585858585858587, 'learning_rate': 'constant', 'penalty': 'l2'}\n",
      "\t[79882]: 0.562 (+/-0.279) for {'alpha': 1.0, 'eta0': 0.8585858585858587, 'learning_rate': 'optimal', 'penalty': 'l1'}\n",
      "\t[79883]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.8585858585858587, 'learning_rate': 'optimal', 'penalty': 'l2'}\n",
      "\t[79884]: 0.571 (+/-0.301) for {'alpha': 1.0, 'eta0': 0.8585858585858587, 'learning_rate': 'invscaling', 'penalty': 'l1'}\n",
      "\t[79885]: 0.752 (+/-0.251) for {'alpha': 1.0, 'eta0': 0.8585858585858587, 'learning_rate': 'invscaling', 'penalty': 'l2'}\n",
      "\t[79886]: 0.514 (+/-0.321) for {'alpha': 1.0, 'eta0': 0.8585858585858587, 'learning_rate': 'adaptive', 'penalty': 'l1'}\n",
      "\t[79887]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.8585858585858587, 'learning_rate': 'adaptive', 'penalty': 'l2'}\n",
      "\t[79888]: 0.324 (+/-0.071) for {'alpha': 1.0, 'eta0': 0.8686868686868687, 'learning_rate': 'constant', 'penalty': 'l1'}\n",
      "\t[79889]: 0.324 (+/-0.071) for {'alpha': 1.0, 'eta0': 0.8686868686868687, 'learning_rate': 'constant', 'penalty': 'l2'}\n",
      "\t[79890]: 0.486 (+/-0.348) for {'alpha': 1.0, 'eta0': 0.8686868686868687, 'learning_rate': 'optimal', 'penalty': 'l1'}\n",
      "\t[79891]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.8686868686868687, 'learning_rate': 'optimal', 'penalty': 'l2'}\n",
      "\t[79892]: 0.438 (+/-0.194) for {'alpha': 1.0, 'eta0': 0.8686868686868687, 'learning_rate': 'invscaling', 'penalty': 'l1'}\n",
      "\t[79893]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.8686868686868687, 'learning_rate': 'invscaling', 'penalty': 'l2'}\n",
      "\t[79894]: 0.457 (+/-0.293) for {'alpha': 1.0, 'eta0': 0.8686868686868687, 'learning_rate': 'adaptive', 'penalty': 'l1'}\n",
      "\t[79895]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.8686868686868687, 'learning_rate': 'adaptive', 'penalty': 'l2'}\n",
      "\t[79896]: 0.448 (+/-0.333) for {'alpha': 1.0, 'eta0': 0.8787878787878789, 'learning_rate': 'constant', 'penalty': 'l1'}\n",
      "\t[79897]: 0.324 (+/-0.071) for {'alpha': 1.0, 'eta0': 0.8787878787878789, 'learning_rate': 'constant', 'penalty': 'l2'}\n",
      "\t[79898]: 0.600 (+/-0.273) for {'alpha': 1.0, 'eta0': 0.8787878787878789, 'learning_rate': 'optimal', 'penalty': 'l1'}\n",
      "\t[79899]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.8787878787878789, 'learning_rate': 'optimal', 'penalty': 'l2'}\n",
      "\t[79900]: 0.667 (+/-0.104) for {'alpha': 1.0, 'eta0': 0.8787878787878789, 'learning_rate': 'invscaling', 'penalty': 'l1'}\n",
      "\t[79901]: 0.667 (+/-0.085) for {'alpha': 1.0, 'eta0': 0.8787878787878789, 'learning_rate': 'invscaling', 'penalty': 'l2'}\n",
      "\t[79902]: 0.486 (+/-0.378) for {'alpha': 1.0, 'eta0': 0.8787878787878789, 'learning_rate': 'adaptive', 'penalty': 'l1'}\n",
      "\t[79903]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.8787878787878789, 'learning_rate': 'adaptive', 'penalty': 'l2'}\n",
      "\t[79904]: 0.324 (+/-0.038) for {'alpha': 1.0, 'eta0': 0.888888888888889, 'learning_rate': 'constant', 'penalty': 'l1'}\n",
      "\t[79905]: 0.343 (+/-0.071) for {'alpha': 1.0, 'eta0': 0.888888888888889, 'learning_rate': 'constant', 'penalty': 'l2'}\n",
      "\t[79906]: 0.629 (+/-0.212) for {'alpha': 1.0, 'eta0': 0.888888888888889, 'learning_rate': 'optimal', 'penalty': 'l1'}\n",
      "\t[79907]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.888888888888889, 'learning_rate': 'optimal', 'penalty': 'l2'}\n",
      "\t[79908]: 0.524 (+/-0.263) for {'alpha': 1.0, 'eta0': 0.888888888888889, 'learning_rate': 'invscaling', 'penalty': 'l1'}\n",
      "\t[79909]: 0.648 (+/-0.143) for {'alpha': 1.0, 'eta0': 0.888888888888889, 'learning_rate': 'invscaling', 'penalty': 'l2'}\n",
      "\t[79910]: 0.457 (+/-0.344) for {'alpha': 1.0, 'eta0': 0.888888888888889, 'learning_rate': 'adaptive', 'penalty': 'l1'}\n",
      "\t[79911]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.888888888888889, 'learning_rate': 'adaptive', 'penalty': 'l2'}\n",
      "\t[79912]: 0.467 (+/-0.251) for {'alpha': 1.0, 'eta0': 0.8989898989898991, 'learning_rate': 'constant', 'penalty': 'l1'}\n",
      "\t[79913]: 0.333 (+/-0.060) for {'alpha': 1.0, 'eta0': 0.8989898989898991, 'learning_rate': 'constant', 'penalty': 'l2'}\n",
      "\t[79914]: 0.571 (+/-0.209) for {'alpha': 1.0, 'eta0': 0.8989898989898991, 'learning_rate': 'optimal', 'penalty': 'l1'}\n",
      "\t[79915]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.8989898989898991, 'learning_rate': 'optimal', 'penalty': 'l2'}\n",
      "\t[79916]: 0.552 (+/-0.311) for {'alpha': 1.0, 'eta0': 0.8989898989898991, 'learning_rate': 'invscaling', 'penalty': 'l1'}\n",
      "\t[79917]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.8989898989898991, 'learning_rate': 'invscaling', 'penalty': 'l2'}\n",
      "\t[79918]: 0.533 (+/-0.368) for {'alpha': 1.0, 'eta0': 0.8989898989898991, 'learning_rate': 'adaptive', 'penalty': 'l1'}\n",
      "\t[79919]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.8989898989898991, 'learning_rate': 'adaptive', 'penalty': 'l2'}\n",
      "\t[79920]: 0.343 (+/-0.038) for {'alpha': 1.0, 'eta0': 0.9090909090909092, 'learning_rate': 'constant', 'penalty': 'l1'}\n",
      "\t[79921]: 0.352 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.9090909090909092, 'learning_rate': 'constant', 'penalty': 'l2'}\n",
      "\t[79922]: 0.524 (+/-0.217) for {'alpha': 1.0, 'eta0': 0.9090909090909092, 'learning_rate': 'optimal', 'penalty': 'l1'}\n",
      "\t[79923]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.9090909090909092, 'learning_rate': 'optimal', 'penalty': 'l2'}\n",
      "\t[79924]: 0.457 (+/-0.286) for {'alpha': 1.0, 'eta0': 0.9090909090909092, 'learning_rate': 'invscaling', 'penalty': 'l1'}\n",
      "\t[79925]: 0.610 (+/-0.327) for {'alpha': 1.0, 'eta0': 0.9090909090909092, 'learning_rate': 'invscaling', 'penalty': 'l2'}\n",
      "\t[79926]: 0.514 (+/-0.321) for {'alpha': 1.0, 'eta0': 0.9090909090909092, 'learning_rate': 'adaptive', 'penalty': 'l1'}\n",
      "\t[79927]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.9090909090909092, 'learning_rate': 'adaptive', 'penalty': 'l2'}\n",
      "\t[79928]: 0.333 (+/-0.060) for {'alpha': 1.0, 'eta0': 0.9191919191919192, 'learning_rate': 'constant', 'penalty': 'l1'}\n",
      "\t[79929]: 0.333 (+/-0.085) for {'alpha': 1.0, 'eta0': 0.9191919191919192, 'learning_rate': 'constant', 'penalty': 'l2'}\n",
      "\t[79930]: 0.505 (+/-0.322) for {'alpha': 1.0, 'eta0': 0.9191919191919192, 'learning_rate': 'optimal', 'penalty': 'l1'}\n",
      "\t[79931]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.9191919191919192, 'learning_rate': 'optimal', 'penalty': 'l2'}\n",
      "\t[79932]: 0.514 (+/-0.363) for {'alpha': 1.0, 'eta0': 0.9191919191919192, 'learning_rate': 'invscaling', 'penalty': 'l1'}\n",
      "\t[79933]: 0.638 (+/-0.305) for {'alpha': 1.0, 'eta0': 0.9191919191919192, 'learning_rate': 'invscaling', 'penalty': 'l2'}\n",
      "\t[79934]: 0.581 (+/-0.279) for {'alpha': 1.0, 'eta0': 0.9191919191919192, 'learning_rate': 'adaptive', 'penalty': 'l1'}\n",
      "\t[79935]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.9191919191919192, 'learning_rate': 'adaptive', 'penalty': 'l2'}\n",
      "\t[79936]: 0.333 (+/-0.060) for {'alpha': 1.0, 'eta0': 0.9292929292929294, 'learning_rate': 'constant', 'penalty': 'l1'}\n",
      "\t[79937]: 0.371 (+/-0.038) for {'alpha': 1.0, 'eta0': 0.9292929292929294, 'learning_rate': 'constant', 'penalty': 'l2'}\n",
      "\t[79938]: 0.581 (+/-0.348) for {'alpha': 1.0, 'eta0': 0.9292929292929294, 'learning_rate': 'optimal', 'penalty': 'l1'}\n",
      "\t[79939]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.9292929292929294, 'learning_rate': 'optimal', 'penalty': 'l2'}\n",
      "\t[79940]: 0.533 (+/-0.309) for {'alpha': 1.0, 'eta0': 0.9292929292929294, 'learning_rate': 'invscaling', 'penalty': 'l1'}\n",
      "\t[79941]: 0.571 (+/-0.217) for {'alpha': 1.0, 'eta0': 0.9292929292929294, 'learning_rate': 'invscaling', 'penalty': 'l2'}\n",
      "\t[79942]: 0.657 (+/-0.140) for {'alpha': 1.0, 'eta0': 0.9292929292929294, 'learning_rate': 'adaptive', 'penalty': 'l1'}\n",
      "\t[79943]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.9292929292929294, 'learning_rate': 'adaptive', 'penalty': 'l2'}\n",
      "\t[79944]: 0.333 (+/-0.060) for {'alpha': 1.0, 'eta0': 0.9393939393939394, 'learning_rate': 'constant', 'penalty': 'l1'}\n",
      "\t[79945]: 0.324 (+/-0.071) for {'alpha': 1.0, 'eta0': 0.9393939393939394, 'learning_rate': 'constant', 'penalty': 'l2'}\n",
      "\t[79946]: 0.457 (+/-0.311) for {'alpha': 1.0, 'eta0': 0.9393939393939394, 'learning_rate': 'optimal', 'penalty': 'l1'}\n",
      "\t[79947]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.9393939393939394, 'learning_rate': 'optimal', 'penalty': 'l2'}\n",
      "\t[79948]: 0.648 (+/-0.222) for {'alpha': 1.0, 'eta0': 0.9393939393939394, 'learning_rate': 'invscaling', 'penalty': 'l1'}\n",
      "\t[79949]: 0.724 (+/-0.185) for {'alpha': 1.0, 'eta0': 0.9393939393939394, 'learning_rate': 'invscaling', 'penalty': 'l2'}\n",
      "\t[79950]: 0.657 (+/-0.140) for {'alpha': 1.0, 'eta0': 0.9393939393939394, 'learning_rate': 'adaptive', 'penalty': 'l1'}\n",
      "\t[79951]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.9393939393939394, 'learning_rate': 'adaptive', 'penalty': 'l2'}\n",
      "\t[79952]: 0.457 (+/-0.267) for {'alpha': 1.0, 'eta0': 0.9494949494949496, 'learning_rate': 'constant', 'penalty': 'l1'}\n",
      "\t[79953]: 0.343 (+/-0.071) for {'alpha': 1.0, 'eta0': 0.9494949494949496, 'learning_rate': 'constant', 'penalty': 'l2'}\n",
      "\t[79954]: 0.467 (+/-0.304) for {'alpha': 1.0, 'eta0': 0.9494949494949496, 'learning_rate': 'optimal', 'penalty': 'l1'}\n",
      "\t[79955]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.9494949494949496, 'learning_rate': 'optimal', 'penalty': 'l2'}\n",
      "\t[79956]: 0.438 (+/-0.285) for {'alpha': 1.0, 'eta0': 0.9494949494949496, 'learning_rate': 'invscaling', 'penalty': 'l1'}\n",
      "\t[79957]: 0.648 (+/-0.097) for {'alpha': 1.0, 'eta0': 0.9494949494949496, 'learning_rate': 'invscaling', 'penalty': 'l2'}\n",
      "\t[79958]: 0.476 (+/-0.356) for {'alpha': 1.0, 'eta0': 0.9494949494949496, 'learning_rate': 'adaptive', 'penalty': 'l1'}\n",
      "\t[79959]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.9494949494949496, 'learning_rate': 'adaptive', 'penalty': 'l2'}\n",
      "\t[79960]: 0.390 (+/-0.229) for {'alpha': 1.0, 'eta0': 0.9595959595959597, 'learning_rate': 'constant', 'penalty': 'l1'}\n",
      "\t[79961]: 0.333 (+/-0.060) for {'alpha': 1.0, 'eta0': 0.9595959595959597, 'learning_rate': 'constant', 'penalty': 'l2'}\n",
      "\t[79962]: 0.486 (+/-0.378) for {'alpha': 1.0, 'eta0': 0.9595959595959597, 'learning_rate': 'optimal', 'penalty': 'l1'}\n",
      "\t[79963]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.9595959595959597, 'learning_rate': 'optimal', 'penalty': 'l2'}\n",
      "\t[79964]: 0.600 (+/-0.286) for {'alpha': 1.0, 'eta0': 0.9595959595959597, 'learning_rate': 'invscaling', 'penalty': 'l1'}\n",
      "\t[79965]: 0.629 (+/-0.298) for {'alpha': 1.0, 'eta0': 0.9595959595959597, 'learning_rate': 'invscaling', 'penalty': 'l2'}\n",
      "\t[79966]: 0.533 (+/-0.321) for {'alpha': 1.0, 'eta0': 0.9595959595959597, 'learning_rate': 'adaptive', 'penalty': 'l1'}\n",
      "\t[79967]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.9595959595959597, 'learning_rate': 'adaptive', 'penalty': 'l2'}\n",
      "\t[79968]: 0.333 (+/-0.060) for {'alpha': 1.0, 'eta0': 0.9696969696969697, 'learning_rate': 'constant', 'penalty': 'l1'}\n",
      "\t[79969]: 0.362 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.9696969696969697, 'learning_rate': 'constant', 'penalty': 'l2'}\n",
      "\t[79970]: 0.505 (+/-0.311) for {'alpha': 1.0, 'eta0': 0.9696969696969697, 'learning_rate': 'optimal', 'penalty': 'l1'}\n",
      "\t[79971]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.9696969696969697, 'learning_rate': 'optimal', 'penalty': 'l2'}\n",
      "\t[79972]: 0.571 (+/-0.289) for {'alpha': 1.0, 'eta0': 0.9696969696969697, 'learning_rate': 'invscaling', 'penalty': 'l1'}\n",
      "\t[79973]: 0.524 (+/-0.356) for {'alpha': 1.0, 'eta0': 0.9696969696969697, 'learning_rate': 'invscaling', 'penalty': 'l2'}\n",
      "\t[79974]: 0.657 (+/-0.140) for {'alpha': 1.0, 'eta0': 0.9696969696969697, 'learning_rate': 'adaptive', 'penalty': 'l1'}\n",
      "\t[79975]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.9696969696969697, 'learning_rate': 'adaptive', 'penalty': 'l2'}\n",
      "\t[79976]: 0.343 (+/-0.071) for {'alpha': 1.0, 'eta0': 0.9797979797979799, 'learning_rate': 'constant', 'penalty': 'l1'}\n",
      "\t[79977]: 0.381 (+/-0.159) for {'alpha': 1.0, 'eta0': 0.9797979797979799, 'learning_rate': 'constant', 'penalty': 'l2'}\n",
      "\t[79978]: 0.467 (+/-0.368) for {'alpha': 1.0, 'eta0': 0.9797979797979799, 'learning_rate': 'optimal', 'penalty': 'l1'}\n",
      "\t[79979]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.9797979797979799, 'learning_rate': 'optimal', 'penalty': 'l2'}\n",
      "\t[79980]: 0.543 (+/-0.245) for {'alpha': 1.0, 'eta0': 0.9797979797979799, 'learning_rate': 'invscaling', 'penalty': 'l1'}\n",
      "\t[79981]: 0.676 (+/-0.111) for {'alpha': 1.0, 'eta0': 0.9797979797979799, 'learning_rate': 'invscaling', 'penalty': 'l2'}\n",
      "\t[79982]: 0.524 (+/-0.301) for {'alpha': 1.0, 'eta0': 0.9797979797979799, 'learning_rate': 'adaptive', 'penalty': 'l1'}\n",
      "\t[79983]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.9797979797979799, 'learning_rate': 'adaptive', 'penalty': 'l2'}\n",
      "\t[79984]: 0.324 (+/-0.071) for {'alpha': 1.0, 'eta0': 0.98989898989899, 'learning_rate': 'constant', 'penalty': 'l1'}\n",
      "\t[79985]: 0.343 (+/-0.071) for {'alpha': 1.0, 'eta0': 0.98989898989899, 'learning_rate': 'constant', 'penalty': 'l2'}\n",
      "\t[79986]: 0.533 (+/-0.368) for {'alpha': 1.0, 'eta0': 0.98989898989899, 'learning_rate': 'optimal', 'penalty': 'l1'}\n",
      "\t[79987]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.98989898989899, 'learning_rate': 'optimal', 'penalty': 'l2'}\n",
      "\t[79988]: 0.505 (+/-0.322) for {'alpha': 1.0, 'eta0': 0.98989898989899, 'learning_rate': 'invscaling', 'penalty': 'l1'}\n",
      "\t[79989]: 0.619 (+/-0.256) for {'alpha': 1.0, 'eta0': 0.98989898989899, 'learning_rate': 'invscaling', 'penalty': 'l2'}\n",
      "\t[79990]: 0.457 (+/-0.293) for {'alpha': 1.0, 'eta0': 0.98989898989899, 'learning_rate': 'adaptive', 'penalty': 'l1'}\n",
      "\t[79991]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 0.98989898989899, 'learning_rate': 'adaptive', 'penalty': 'l2'}\n",
      "\t[79992]: 0.324 (+/-0.038) for {'alpha': 1.0, 'eta0': 1.0, 'learning_rate': 'constant', 'penalty': 'l1'}\n",
      "\t[79993]: 0.343 (+/-0.071) for {'alpha': 1.0, 'eta0': 1.0, 'learning_rate': 'constant', 'penalty': 'l2'}\n",
      "\t[79994]: 0.495 (+/-0.299) for {'alpha': 1.0, 'eta0': 1.0, 'learning_rate': 'optimal', 'penalty': 'l1'}\n",
      "\t[79995]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 1.0, 'learning_rate': 'optimal', 'penalty': 'l2'}\n",
      "\t[79996]: 0.505 (+/-0.364) for {'alpha': 1.0, 'eta0': 1.0, 'learning_rate': 'invscaling', 'penalty': 'l1'}\n",
      "\t[79997]: 0.657 (+/-0.093) for {'alpha': 1.0, 'eta0': 1.0, 'learning_rate': 'invscaling', 'penalty': 'l2'}\n",
      "\t[79998]: 0.400 (+/-0.273) for {'alpha': 1.0, 'eta0': 1.0, 'learning_rate': 'adaptive', 'penalty': 'l1'}\n",
      "\t[79999]: 0.695 (+/-0.047) for {'alpha': 1.0, 'eta0': 1.0, 'learning_rate': 'adaptive', 'penalty': 'l2'}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.89      0.94        18\n",
      "           2       0.85      1.00      0.92        11\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.95      0.96      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "\n",
      "SEARCH TIME: 562.17 sec\n",
      "CTOR for best model: SGDClassifier(alpha=0.010101010101010102, eta0=0.36363636363636365,\n",
      "              penalty='l1')\n",
      "\n",
      "best: dat=iris, score=1.00000, model=SGDClassifier(alpha=0.010101010101010102,eta0=0.36363636363636365,learning_rate='optimal',penalty='l1')\n",
      "\n",
      "OK(grid-search)\n",
      "/home/morten/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=None as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from threading import Thread\n",
    "from time import sleep\n",
    "\n",
    "def print_time():\n",
    "    while(finished == False):\n",
    "        print(f\"Time since start: {time() - start:.2f}\")\n",
    "        sleep(10)\n",
    "        \n",
    "\n",
    "# Setup data\n",
    "X_train, X_test, y_train, y_test = LoadAndSetupData(\n",
    "    'iris')  # 'iris', 'moon', or 'mnist'\n",
    "\n",
    "# Setup search parameters\n",
    "model = SGDClassifier()\n",
    "\n",
    "penalty = ('l1', 'l2')\n",
    "alpha = np.linspace(start=1E-20, stop=1, num=100)\n",
    "learning_rate = ['constant', 'optimal', 'invscaling', 'adaptive']\n",
    "eta0 = np.linspace(start=1E-20, stop=1, num=100)\n",
    "\n",
    "tuning_parameters = {\n",
    "    'penalty': penalty, \n",
    "    'alpha': alpha,\n",
    "    'learning_rate': learning_rate,\n",
    "    'eta0': eta0\n",
    "}\n",
    "\n",
    "CV = 5\n",
    "VERBOSE = 1\n",
    "\n",
    "# Run GridSearchCV for the model\n",
    "start = time()\n",
    "finished = False\n",
    "thread = Thread(target = print_time, args = [])\n",
    "thread.start()\n",
    "grid_tuned = GridSearchCV(model,\n",
    "                          tuning_parameters,\n",
    "                          cv=CV,\n",
    "                          scoring='f1_micro',\n",
    "                          verbose=VERBOSE,\n",
    "                          n_jobs=-1)\n",
    "grid_tuned.fit(X_train, y_train)\n",
    "t = time() - start\n",
    "finished = True\n",
    "\n",
    "# Report result\n",
    "b0, m0 = FullReport(grid_tuned, X_test, y_test, t)\n",
    "print('OK(grid-search)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}